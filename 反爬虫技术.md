
程序员总是希望能够让计算机自动化地处理信息。我们想要写一个程序，去自动下载电影，自动网上选课，自动买票，自动下载粉丝数数据，便于绘制数据可视化，或者下载其他什么数据便于写毕业论文。这种技术叫做爬虫技术。

我可以下一个断言：这是最实用的技术，之一。同时这种技术也是最简单的。我们要做的是写一个客户端，它发送请求给服务器，服务器根据请求返回数据。

但我们开发服务器的人希望服务的是用户，而不是程序。一方面有人写的爬虫有问题，我曾经就被爬过，每天向我的服务器发送几百万个请求，服务器容易炸不说，发送信息是要交流量费的，一觉醒来，一个大会员的没了。另一方面机器人抢票，不公平，像什么12306，都是反爬做到极致的网站。其实我可以说是身进百战，见的多了。今天就来和大家讨论一下，怎么反制爬虫。这个视频主要以交流心得为主，我说的不一定都对，如果有错误感谢指正。

## 检测爬虫

反爬虫技术的一种方式是：添加一种机制，识别客户端究竟是真人操作还是程序发起的请求。

最简单的方式是验证请求头。其实每一个被发送的请求都会标记自己是什么客户端发起的。而默认情况下，爬虫程序的请求头和其他请求头是不一样的。比如你用 Python 的 Requests 库的话，user-agent 就会带有 Requests，如果使用 Scrapy 就会带有 Screpy。但是这个只需要一行代码就可以伪造成和普通用户一样的请求头，所以没有什么效果。用这种方式唯一的好处就是不会误伤。因为正经用户不可能随便修改自己的请求头。

另外也可以根据 IP 地址来反爬虫。大部分长期的爬虫会把服务放在云服务器上，而从 IP 地址可以很轻松地判断爬虫是不是从服务器上发起的，服务器一检查，这个 IP 居然来自于阿里云，直接封了，一封一个准。更加常用的是检测访问频率，一个 IP 访问频率到了阈值，那么就封掉这个 IP。但这样也有一点缺点，因为现在IPv6还没有普及，一个IP地址都是很多人公用的。如果有个舍友搞骚操作被封了，整个宿舍一起遭殃，很容易误封。

## 加密数据

另外一种方式是加密数据。这是一种更加常用的方式。它不专注于识别爬虫，而是增加爬虫程序编写的难度。事实上各大公司都应用了数据加密。比如将数字编号转换成毫无意义的字符串。其实这是一个大工程。这波操作增加了系统的复杂度，APP端、Web端、服务端都需要迎合这个新的系统做出修改。但是事实证明这波操作没有什么意义。仅仅几小时就被民间大神找到了转换公式，投入的工时变成了完全的浪费。

百度指数更加小儿科一些，连我这个信息安全素养几乎为0的人也能分分钟破解。他的加密是这样的，在某个请求之中，服务器会返回一串神秘代码，类似`LjIpG6QRKw50dON8,7+%0592.64-31`, 而在另外一个请求值周返回一大串乱码。实际上，之前的神秘代码是一个对照表，前面一半是密文，后面一半是它的译文。用这个密码表就可以轻松地吧乱码翻译成一个数组数据。比如说

相比之下，字节跳动的加密要恶心很多。字节跳动系的产品采用的是前端生成签名的机制。输入url和参数，经过一个层层套娃的算法，然后输出一个签名。根据请求的不同，这个签名也会有所不同。想要破解这种密码，你得在截取出这个生成签名的函数。这对爬虫开发人员的前端水平有一定的要求，但只要了解原理也不是不能被破解的。

## 混淆数据

还有一种方式是混淆数据。这种方式更有意思一些。这种技术并不是干掉爬虫，而是喂给爬虫虚假的数据。

其中有一种很神奇的方式。它给所有人的都是错误的数据，但是用人的肉眼去看，数据的显示却是正确的。比如服务器发来 1234，显示出来居然是 3142。其中的奥妙就是使用了特殊的字体。这个字体就很奇葩，它把 1 写成 3 的样子，如果你看纯数据，那就是 1，但显示出来，它是 3。这个数字实际上就应该是3，但是服务器偏偏发过来的是1，只有在服务方特别提供的字体下看到的才是正确的数字。这种方式找到了计算机和普通用户的一个不同之处，那就是计算机只会处理纯数据，而不会真的去观看数据呈现出来的样子。

虽然这种方式很有趣，但我不推荐使用。这种方式如果被发现了，也很容易被攻破。只要获取相应的字体文件，就能还原出正确的映射关系。同时它污染了自己的接口，内部人员调试起来也会非常不爽。

## 全自动区分计算机和人类的公開图灵测试

这才是最有技术含量的技术。大家对这个名词可能比较陌生，但大家都知道他的俗称，那就是验证码。我知道大家都不喜欢验证码这种东西。验证码系统是比较昂贵的，接入也比较复杂，但这确实是抵御爬虫的终极手段。想要破解验证码，需要更加牛逼的技术，比如类似图中所示的验证码，首先需要计算机视觉技术识别出问题信息，再通过自然语言处理理解内容，再识别每张图所呈现的内容，还需要使用奇慢无比的无头浏览器模拟，成功率也不高。更可怕的是有些验证码会故意出一些人类可能误解的题目，而期望输入验证码的人犯错。这种反爬虫往往和用户关系系统结合，针对账号级别进行封禁。要知道国内实名上网，想搞一个账号也不容易，特别是有些网站账号是要付费的。因此要对抗这种反爬虫策略需要更高的成本。

---

## 结语

我大致和大家讨论了几种我见过的爬虫和反爬虫的套路。这种攻防不断技术升级，有一种道高一尺，魔高一丈的感觉。其实爬虫技术是很难被彻底杜绝的。进攻方需要耗费时间精力和金钱面对防御方的反制手段，而防御方需要尽可能提高进攻方的成本。我曾经运营了一个网站，应用了很多爬虫相关的技术。目睹了一个网站是怎么从几乎不设防，到如今动不动就 412，甚至有时候会误伤普通用户。其实技术上的问题，对于野生程序员来说，都不是什么真正的问题。但每当这种反爬手段健壮一层，那些开发者的热情就冷淡一分。爬虫的编写者大多是应用自己学到的技术，方便自己也方便他人。他们没有动机，也没有胆量，去拿这些数据牟利。其实国内外有很多平台愿意开放自己的 API，提供开发者正规的渠道增强他们的应用程序。我希望有一天，这种开放的精神也能在这里延续。
