今天我想和大家讨论一下爬虫和反爬虫的技术。我说的不一定完全正确，感谢小伙伴们批评指正。

先下一个断言：**数据这种东西是非常有价值的**。无论是写论文，做研究，甚至是玩游戏，都需要数据。

如果我想要绘制出我的粉丝数变化曲线，我只要每隔一段时间刷新一下网页，把我的粉丝数和当下时间抄录进excel就可以生成表格。

这一系列动作，非常**机械简单无脑**。所以很适合编写一个固定的程序让它定时去完成。这样的一种，发送请求，获取数据，再保存下来的程序就叫做**爬虫**。

因此再下一个断言：爬虫程序是世界上最**简单**，也是最**实用**的程序之一。

理论上你可以编写爬虫，获取一切你能看得到的数据。

但现实往往是，对方会设置重重障碍，不希望你能爬取他的数据。

这是可以理解的。如果B站的所有数据被敌台爬了，那么敌台就可以分析这些数据，把有潜力的UP主挖走。另一方面，有些人写的爬虫太过于暴力，一秒钟撸一万次，直接把平台搞炸，也会影响正常用户的使用体验。

这种防御爬虫的措施，叫做**反爬虫技术**。这种技术的目的在于，识别出请求到底来自于正常用户还是一段程序。他听起来很容易让人联想到大名鼎鼎的图灵测试。

而反爬虫技术的各种手段，也不是无懈可击的。因此也有反反爬虫技术，无限套娃。这就很有意思了。今天主要就是想和大家讨论一下我见过的爬虫与反爬虫技术。

---

## 验证User-Agent

验证请求头是最简单的反爬虫技术。每个请求其实都会标记自己是怎么产生的。比如这个请求是浏览器产生的。而这个请求

---

## 请求频率限制

请求频率的限制

## 验证码

验证码功能的全称很牛逼， (CAPTCHA) 全名为「全自动区分计算机和人类的公开图灵测试」

## 加密

## IP封禁
